#+TITLE: å¿«é€Ÿå…¥é—¨ GPT-4 Vison
#+STARTUP: showall hidestars indent inlineimages
#+PROPERTY: header-args:jupyter-python :session 2024äººå·¥æ™ºèƒ½å­¦ä¹ -gpt-4v text/plain

ä»å†å²ä¸Šçœ‹ï¼Œè¯­è¨€æ¨¡å‹ç³»ç»Ÿä»…æ¥å—*æ–‡æœ¬*ä½œä¸ºè¾“å…¥ã€‚ä½†æ˜¯å•ä¸€çš„è¾“å…¥å½¢å¼ï¼Œé™åˆ¶äº†å¤§æ¨¡å‹çš„åº”ç”¨è½åœ°èŒƒå›´ã€‚

éšç€æŠ€æœ¯å‘å±•ï¼ŒOpenAI å¼€å‘çš„ GPT-4 Turbo with Visionï¼ˆç®€ç§°
GPT-4Vï¼‰å…è®¸æ¨¡å‹æ¥æ”¶*å›¾åƒ*ä½œä¸ºè¾“å…¥ï¼Œå¹¶å›ç­”å…³äºå®ƒä»¬çš„é—®é¢˜ã€‚

ğŸ“¢æ³¨æ„ï¼Œç›®å‰åœ¨ Assistants API ä¸­ä½¿ç”¨ GPT-4 æ—¶è¿˜ä¸æ”¯æŒå›¾åƒè¾“å…¥ã€‚

* ä½¿ç”¨ GPT-4V è¯†åˆ«çº¿ä¸Šå›¾åƒï¼ˆURLï¼‰
https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg

#+begin_src jupyter-python
  from openai import OpenAI

  client = OpenAI(base_url='https://api.xty.app/v1')

  response = client.chat.completions.create(
    model="gpt-4-turbo",
    messages=[
      {
        "role": "user",
        "content": [
          {"type": "text", "text": "ä»‹ç»ä¸‹è¿™å¹…å›¾?"},
          {
            "type": "image_url",
            "image_url": {
              "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
            },
          },
        ],
      }
    ],
    max_tokens=300,
  )

  print(response.choices[0])
#+end_src

#+RESULTS:

#+begin_example
  Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='è¿™å¹…å›¾å‘ˆç°äº†ä¸€ä¸ªå®é™ç¾ä¸½çš„è‡ªç„¶æ™¯è§‚ã€‚å›¾ä¸­çš„ä¸»è¦ç‰¹ç‚¹æ˜¯ä¸€æ¡æœ¨åˆ¶çš„æ ˆé“ï¼Œå®ƒç©¿è¶Šåœ¨éƒéƒè‘±è‘±çš„è‰åœ°ä¸Šï¼Œå¼•å‘è¿œå¤„çœ‹ä¸åˆ°çš„ç»ˆç‚¹ã€‚è‰åœ°ä¸Šè¦†ç›–ç€èŒ‚å¯†çš„ç»¿è‰²æ¤è¢«ï¼Œæ˜¾ç¤ºå‡ºç”Ÿæœºå‹ƒå‹ƒçš„æ˜¥å¤å­£èŠ‚ã€‚èƒŒæ™¯ä¸­å¤©ç©ºå‘ˆç°å‡ºæ¾„æ¸…çš„è“è‰²ï¼Œç‚¹ç¼€ç€å‡ æœµè½»ç›ˆçš„ç™½äº‘ï¼Œå¢æ·»äº†ä¸€ç§å®é™å’Œå¹³å’Œçš„æ°›å›´ã€‚\n\næ•´ä¸ªåœºæ™¯å…‰çº¿å……è¶³ï¼Œé˜³å…‰å’Œè“å¤©ä¸ç»¿è‰²æ¤è¢«çš„å¯¹æ¯”ä»¤äººæ„Ÿè§‰æ¸…æ–°æ„‰å¿«ã€‚è¿™æ ·çš„ç¯å¢ƒå¯èƒ½æ˜¯ç†æƒ³çš„å¾’æ­¥æ—…è¡Œåœ°ç‚¹ï¼Œæä¾›äº†äº²è¿‘è‡ªç„¶å’Œæ”¾æ¾å¿ƒæƒ…çš„å®Œç¾æœºä¼šã€‚æ•´ä½“ä¸Šï¼Œè¿™å¹…å›¾ä¼ è¾¾äº†å¤§è‡ªç„¶çš„å®é™ä¸å’Œè°ï¼Œæ˜¯è§‚èµå’Œä½“éªŒè‡ªç„¶ç¾æ™¯çš„ä¸€ç§', role='assistant', function_call=None, tool_calls=None))
#+end_example

#+begin_src jupyter-python
  response.choices[0].message.content
#+end_src

#+RESULTS:
: 'è¿™å¹…å›¾å‘ˆç°äº†ä¸€ä¸ªå®é™ç¾ä¸½çš„è‡ªç„¶æ™¯è§‚ã€‚å›¾ä¸­çš„ä¸»è¦ç‰¹ç‚¹æ˜¯ä¸€æ¡æœ¨åˆ¶çš„æ ˆé“ï¼Œå®ƒç©¿è¶Šåœ¨éƒéƒè‘±è‘±çš„è‰åœ°ä¸Šï¼Œå¼•å‘è¿œå¤„çœ‹ä¸åˆ°çš„ç»ˆç‚¹ã€‚è‰åœ°ä¸Šè¦†ç›–ç€èŒ‚å¯†çš„ç»¿è‰²æ¤è¢«ï¼Œæ˜¾ç¤ºå‡ºç”Ÿæœºå‹ƒå‹ƒçš„æ˜¥å¤å­£èŠ‚ã€‚èƒŒæ™¯ä¸­å¤©ç©ºå‘ˆç°å‡ºæ¾„æ¸…çš„è“è‰²ï¼Œç‚¹ç¼€ç€å‡ æœµè½»ç›ˆçš„ç™½äº‘ï¼Œå¢æ·»äº†ä¸€ç§å®é™å’Œå¹³å’Œçš„æ°›å›´ã€‚\n\næ•´ä¸ªåœºæ™¯å…‰çº¿å……è¶³ï¼Œé˜³å…‰å’Œè“å¤©ä¸ç»¿è‰²æ¤è¢«çš„å¯¹æ¯”ä»¤äººæ„Ÿè§‰æ¸…æ–°æ„‰å¿«ã€‚è¿™æ ·çš„ç¯å¢ƒå¯èƒ½æ˜¯ç†æƒ³çš„å¾’æ­¥æ—…è¡Œåœ°ç‚¹ï¼Œæä¾›äº†äº²è¿‘è‡ªç„¶å’Œæ”¾æ¾å¿ƒæƒ…çš„å®Œç¾æœºä¼šã€‚æ•´ä½“ä¸Šï¼Œè¿™å¹…å›¾ä¼ è¾¾äº†å¤§è‡ªç„¶çš„å®é™ä¸å’Œè°ï¼Œæ˜¯è§‚èµå’Œä½“éªŒè‡ªç„¶ç¾æ™¯çš„ä¸€ç§'

** å°è£…æˆä¸€ä¸ªå‡½æ•° query_image_description

#+begin_src jupyter-python :response none
  def query_image_description(url, prompt="ä»‹ç»ä¸‹è¿™å¹…å›¾?"):
      client = OpenAI()  # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
    
      # å‘é€è¯·æ±‚ç»™ OpenAI çš„èŠå¤©æ¨¡å‹
      response = client.chat.completions.create(
          model="gpt-4-turbo",  # æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹
          messages=[
              {
                  "role": "user",
                  "content": [
                      {"type": "text", "text": prompt},
                      {"type": "image_url", "image_url": {"url": url}},
                  ],
              }
          ],
          max_tokens=300,
      )
    
      # è¿”å›æ¨¡å‹çš„å“åº”
      return response.choices[0].message.content
#+end_src

** è°ƒç”¨å‡½æ•°æµ‹è¯•
[[https://p6.itc.cn/q_70/images03/20200602/0c267a0d3d814c9783659eb956969ba1.jpeg]]

#+begin_src jupyter-python
  image_url = "https://p6.itc.cn/q_70/images03/20200602/0c267a0d3d814c9783659eb956969ba1.jpeg"
  content = query_image_description(image_url)
  print(content)
#+end_src

#+begin_example
è¿™å¹…å›¾æ˜¯ä¸€ç§å¹½é»˜é£æ ¼çš„æç¬‘æ¯”è¾ƒã€‚å›¾ä¸­å±•ç¤ºäº†ä¸¤ç§ä¸åŒçŠ¶æ€çš„ç‹—ã€‚å·¦è¾¹æ˜¯ä¸€åªè¢«å¹»æƒ³æˆæ‹¥æœ‰éå¸¸å‘è¾¾è‚Œè‚‰ã€ç±»ä¼¼äººç±»å¥ç¾è¿åŠ¨å‘˜èº«ä½“çš„æŸ´çŠ¬ï¼Œé…æ–‡â€œ16å²çš„æˆ‘ï¼Œå·¥ä½œåçš„æˆ‘â€ï¼Œè¡¨è¾¾äº†å¹´è½»æ—¶å……æ»¡æ´»åŠ›å’Œæ¢¦æƒ³çš„çŠ¶æ€ã€‚å³è¾¹çš„æŸ´çŠ¬åˆ™æ˜¾å¾—æ™®é€šã€ç•¥æ˜¾æ†”æ‚´ï¼Œé…æœ‰æ–‡å­—â€œå¥½ç´¯å¥½å›°ã€å¥½æƒ³æ‘¸é±¼ã€çœ‹åˆ°é¸¡è…¿å°±å¼€å¿ƒï¼Œä¸å±äºæˆ‘ã€æˆ‘ä¹Ÿæœ‰å°è‚šè…©ã€è‚‰è‚‰çš„å¾ˆå¯çˆ±â€ï¼Œæç»˜äº†å·¥ä½œåå¯èƒ½æ„Ÿåˆ°ç–²æƒ«ã€å‡å°‘é”»ç‚¼è€Œç•¥æ˜¾å‘ç¦çš„ç°å®çŠ¶æ€ã€‚

è¿™ç§å¯¹æ¯”é€šå¸¸ç”¨æ¥å¹½é»˜åœ°è¡¨è¾¾äººä»¬å¯¹äºç†æƒ³ä¸ç°å®ä¹‹é—´å·®è·çš„æ„Ÿæ…¨ï¼Œå±•ç¤ºäº†è®¸å¤šäººå¯¹äºå¹´è½»æ—¶çš„æ†§
#+end_example

#+begin_src jupyter-python
#+end_src

#+begin_src jupyter-python
#+end_src

** ä½¿ç”¨ GPT-4V è¯†åˆ«æœ¬åœ°å›¾åƒæ–‡ä»¶ï¼ˆBase64ç¼–ç ï¼‰

#+begin_src jupyter-python
from openai import OpenAI
import base64
import requests
import json

client = OpenAI()  # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯

def query_base64_image_description(image_path, prompt="è§£é‡Šä¸‹å›¾é‡Œçš„å†…å®¹ï¼Ÿ", max_tokens=1000):

    # å®ç° Base64 ç¼–ç 
    def encode_image(path):
        with open(path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')

    # è·å–å›¾åƒçš„ Base64 ç¼–ç å­—ç¬¦ä¸²
    base64_image = encode_image(image_path)

    # æ„é€ è¯·æ±‚çš„ HTTP Header
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {client.api_key}"
    }

    # æ„é€ è¯·æ±‚çš„è´Ÿè½½
    payload = {
        "model": "gpt-4-turbo",
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                ]
            }
        ],
        "max_tokens": max_tokens
    }

    # å‘é€ HTTP è¯·æ±‚
    response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload)

    # æ£€æŸ¥å“åº”å¹¶æå–æ‰€éœ€çš„ content å­—æ®µ
    if response.status_code == 200:
        response_data = response.json()
        content = response_data['choices'][0]['message']['content']
        return content
    else:
        return f"Error: {response.status_code}, {response.text}"
#+end_src

*** ä½¿ç”¨ Assistants APIç”Ÿæˆçš„ GDP 40å¹´å¯¹æ¯”æ›²çº¿å›¾
[[./images/gdp_1980_2020.jpg]]

#+begin_src jupyter-python
content = query_base64_image_description("./images/gdp_1980_2020.jpg")
print(content)
#+end_src

#+begin_example
è¿™å¹…å›¾å±•ç¤ºäº†1980å¹´åˆ°2020å¹´é—´ï¼Œç¾å›½ã€ä¸­å›½ã€æ—¥æœ¬å’Œå¾·å›½çš„å›½å†…ç”Ÿäº§æ€»å€¼ï¼ˆGDPï¼‰æ¯”è¾ƒã€‚æ¯ä¸ªå›½å®¶çš„GDPä»¥ä¸‡äº¿ç¾å…ƒä¸ºå•ä½æ ‡å‡ºã€‚ä»å›¾ä¸­å¯ä»¥çœ‹å‡ºï¼š

- **ç¾å›½ï¼ˆè“çº¿ï¼‰**ï¼šGDPæŒç»­å¢é•¿ï¼Œä»1980å¹´çš„çº¦3ä¸‡äº¿ç¾é‡‘å¢é•¿åˆ°2020å¹´çš„è¶…è¿‡20ä¸‡äº¿ç¾é‡‘ã€‚
- **ä¸­å›½ï¼ˆçº¢çº¿ï¼‰**ï¼šè‡ª1980å¹´èµ·ï¼ŒGDPå¢é•¿éå¸¸æ˜¾è‘—ï¼Œä»ä¸åˆ°1ä¸‡äº¿ç¾é‡‘å¢é•¿è‡³æ¥è¿‘15ä¸‡äº¿ç¾é‡‘ã€‚
- **æ—¥æœ¬ï¼ˆç´«çº¿ï¼‰**ï¼š1980å¹´è‡³1995å¹´GDPå¢é•¿æ˜æ˜¾ï¼Œä¹‹åå¢é•¿æ”¾ç¼“ï¼Œå¹¶åœ¨2005å¹´è‡³2015å¹´é—´ä¿æŒç›¸å¯¹å¹³ç¨³ã€‚
- **å¾·å›½ï¼ˆç»¿çº¿ï¼‰**ï¼šGDPå¢é•¿è¾ƒä¸ºå¹³ç¨³ï¼Œä»1980å¹´çš„ä¸åˆ°1ä¸‡äº¿ç¾é‡‘å¢é•¿è‡³2020å¹´çš„çº¦4ä¸‡äº¿ç¾é‡‘ã€‚

æ€»ä½“è€Œè¨€ï¼Œå›¾è¡¨æ¸…æ™°åœ°è¡¨ç¤ºäº†è¿™å››ä¸ªç»æµä½“åœ¨è¿‡å»å››åå¹´é—´çš„ç»æµå¢é•¿æƒ…å†µï¼Œå…¶ä¸­ä¸­å›½çš„å¢é•¿å°¤å…¶å¼•äººæ³¨ç›®ï¼Œæ˜¾ç¤ºäº†å…¶ç»æµçš„è¿…é€Ÿå´›èµ·ã€‚ç¾å›½åˆ™ä¿æŒäº†å…¶å…¨çƒç»æµé¢†å¯¼åœ°ä½çš„å¢é•¿è¶‹åŠ¿ã€‚æ—¥æœ¬åœ¨90å¹´ä»£åå¢é•¿æ”¾ç¼“ï¼Œè€Œå¾·å›½åˆ™æ˜¾ç¤ºå‡ºç¨³å®šçš„å¢é•¿æ¨¡å¼ã€‚
#+end_example

*** ä½¿ç”¨ GPT-4V è¯†åˆ«æ‰‹å†™ä½“ç¬”è®°
[[./images/handwriting_0.jpg]]

#+begin_src jupyter-python
content = query_base64_image_description("./images/handwriting_0.jpg")
print(content)
#+end_src

#+begin_example
è¿™å¼ å›¾ç‰‡æ˜¾ç¤ºçš„æ˜¯ä¸€æœ¬ç¬”è®°æœ¬ä¸Šæ‰‹å†™çš„æ–‡å­—ï¼Œå†…å®¹ä¸»è¦æ¶‰åŠåˆ°è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä¸­çš„è®­ç»ƒæŠ€æœ¯ï¼Œå¦‚Prompt Tuningå’ŒLoRAæŠ€æœ¯ã€‚

1. **Prompt Tuningï¼ˆç®€è¦æ¨¡å‹è°ƒæ•´ï¼‰**ï¼š æåˆ°äº†ä½¿ç”¨Prompt Tuningæ¥è°ƒæ•´ä¸€ä¸ªå°å‹çš„Transformeræ¨¡å‹ã€‚æ­¤å¤„è§£é‡Šäº†è¾“å…¥Xï¼ˆç”±ä¸ªåˆ«è¾“å…¥X1, X2, ..., Xnç»„æˆï¼‰ã€‚æ¯ä¸ªè¾“å…¥é¦–å…ˆé€šè¿‡ä¸€ä¸ªEmbeddingè¿‡ç¨‹è½¬æ¢ï¼Œç„¶åé€šè¿‡Tokenå˜æ¢ã€‚è¾“å‡ºYæ˜¯é€šè¿‡çŸ©é˜µWä¸è½¬æ¢åçš„è¾“å…¥X'ä¹‹é—´çš„ä¹˜æ³•å¾—å‡ºã€‚

2. **Prefix Tuningï¼š** è¿™éƒ¨åˆ†è¯´æ˜äº†Prefix Tuningçš„è¿‡ç¨‹ï¼Œå…¶ä¸­æ·»åŠ äº†å‰ç¼€æƒé‡W_påˆ°åŸå§‹æƒé‡W_jä¸­ï¼Œå¾—åˆ°æ–°çš„æƒé‡W'ç”¨äºç”Ÿæˆè¾“å‡ºYã€‚

3. **LoRAè°ƒæ•´æŠ€æœ¯**ï¼š è¿™éƒ¨åˆ†æ¶‰åŠLinear Re-parameterizationï¼ˆçº¿æ€§é‡æ–°å‚æ•°åŒ–ï¼‰ï¼Œé€šè¿‡è°ƒæ•´çŸ©é˜µÎ”Wï¼ˆé€šè¿‡ä¸¤ä¸ªçŸ©é˜µAå’ŒBçš„ä¹˜ç§¯è¡¨ç¤ºï¼‰æ¥ä¿®æ”¹æƒé‡Wã€‚è¿™æ˜¯ä¸€ç§èŠ‚çœå‚æ•°è°ƒæ•´çš„æ–¹æ³•ï¼Œä½¿åŸæœ‰æ¨¡å‹çš„Wå˜ä¸ºW+Î”Wï¼Œè¿™é‡Œä¹Ÿæ¶‰åŠåˆ°äº†ä¸€äº›çŸ©é˜µè¿ç®—å’Œä¼˜åŒ–ç­–ç•¥ã€‚

å…¶ä¸­è¿˜æåˆ°äº†ä¸¤ä¸ªæ¡ˆä¾‹åˆ†æçš„å­˜å‚¨éœ€æ±‚ï¼šâ€œLLAMAâ€éœ€è¦65GBï¼Œè€Œç»è¿‡LoRAè°ƒæ•´çš„â€œQLLoRAâ€ä»…éœ€è¦48GBã€‚

è¿™äº›ç¬”è®°å¯¹äºç†è§£NLPä¸­ä¸€äº›å…ˆè¿›çš„æ¨¡å‹è°ƒæ•´æŠ€æœ¯ååˆ†æœ‰ç”¨ï¼Œå°¤å…¶å¯¹äºéœ€è¦åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸‹éƒ¨ç½²NLPæ¨¡å‹çš„ç ”ç©¶äººå‘˜æˆ–å®è·µè€…ã€‚
#+end_example

*** åœ¨ Jupyter æ ‡å‡†è¾“å‡ºä¸­æ¸²æŸ“ Markdown æ ¼å¼å†…å®¹

#+begin_src jupyter-python
from IPython.display import display, Markdown

# ä½¿ç”¨ display å’Œ Markdown å‡½æ•°æ˜¾ç¤º Markdown å†…å®¹
display(Markdown(content))
#+end_src

#+begin_example
<IPython.core.display.Markdown object>
#+end_example

[[./images/handwriting_1.jpg]]

#+begin_src jupyter-python
content = query_base64_image_description("./images/handwriting_1.jpg")
display(Markdown(content))
#+end_src

#+begin_example
<IPython.core.display.Markdown object>
#+end_example

#+begin_src jupyter-python
#+end_src

#+begin_src jupyter-python
#+end_src

#+begin_src jupyter-python
#+end_src

* Homework:
** #1
ä½¿ç”¨ GPT-4V è¯†åˆ«å¸¦æœ‰æ‰‹å†™ä½“æ–‡å­—çš„æœ¬åœ°å›¾åƒæ–‡ä»¶ï¼Œåˆ†äº«ç»“æœã€‚

** #2
æ•´åˆ =query_base64_image_description= å‡½æ•°å’Œ Markdown
æ ¼å¼æ¸²æŸ“æ–¹æ³•ï¼Œä½¿å¾—è¾“å‡ºç»“æœæ›´æ˜“é˜…è¯»ã€‚
